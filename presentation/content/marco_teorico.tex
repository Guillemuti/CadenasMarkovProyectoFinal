\section{Marco Teórico}

\begin{frame}{Distancia de Variación Total}
    \begin{definition}
        Sean $\mu_1$ y $\mu_2$ medidas de probabilidad con densidades $f_{\mu_1}$ y $f_{\mu_2}$ respecto a una medida dominante $\lambda$. La \textbf{distancia de variación total} es:
        $$TV(\mu_1, \mu_2) = \frac{1}{2} \int_\Omega \left| f_{\mu_1}(x) - f_{\mu_2}(x) \right| d\lambda(x)$$
    \end{definition}

    \vspace{0.5em}

    \begin{itemize}
        \item<2-> $0 \leq TV(\mu_1, \mu_2) \leq 1$
        \item<3-> Forma equivalente: $TV(\mu_1, \mu_2) = \sup_{A \in \mathcal{F}} |\mu_1(A) - \mu_2(A)|$
        \item<4-> $TV(\mu_1, \mu_2) = 0 \iff \mu_1 = \mu_2$
    \end{itemize}
\end{frame}

\begin{frame}{Coeficiente de Mezcla $\beta$}
    \begin{definition}
        Para un proceso estocástico $\{X_t\}$, el \textbf{coeficiente de mezcla $\beta$} se define como:
        $$\beta(n) = TV\left(\mathcal{L}(X_0, X_n), \mathcal{L}(X_0) \otimes \mathcal{L}(X_n)\right)$$
    \end{definition}

    \vspace{0.3em}

    \begin{block}<2->{Forma Integral}
        {\small $$\beta(n) = \frac{1}{2} \int \int \left| f_{X_0, X_n}(x, y) - f_{X_0}(x) f_{X_n}(y) \right| dx \, dy$$}
    \end{block}

    \vspace{0.3em}

    \begin{itemize}
        \item<3-> $\beta(n)$ mide la \emphasis{dependencia} entre pasado y futuro
        \item<4-> $0 \leq \beta(n) \leq 1$ para todo $n$
        \item<5-> $\beta(n)$ es \highlight{no creciente} en $n$
    \end{itemize}
\end{frame}

\begin{frame}{Procesos $\beta$-Mezclados}
    \begin{block}{Definición}
        Un proceso es \textbf{$\beta$-mezclado} si:
        $$\beta(n) \to 0 \quad \text{cuando} \quad n \to \infty$$
    \end{block}

    \vspace{0.5em}

    \begin{columns}
        \begin{column}{0.5\textwidth}
            \textbf{Interpretación:}
            \begin{itemize}
                \item<2-> Pasado y futuro se vuelven \emphasis{asintóticamente independientes}
                \item<3-> Memoria \highlight{corta}
                \item<4-> Permite CLT y LLN
            \end{itemize}
        \end{column}
        \begin{column}{0.5\textwidth}
            \textbf{NO $\beta$-mezclado:}
            \begin{itemize}
                \item<2-> $\beta(n) \not\to 0$
                \item<3-> Memoria \highlight{larga}
                \item<4-> Dependencia persistente
            \end{itemize}
        \end{column}
    \end{columns}
\end{frame}

\begin{frame}{Propiedades Fundamentales}
    \begin{theorem}[Monotonicidad]
        Para todo $m \leq n$: $\beta(n) \leq \beta(m)$
    \end{theorem}

    \vspace{0.5em}

    \begin{theorem}[Subaditividad]
        $\beta(m+n) \leq \beta(m) + \beta(n)$
    \end{theorem}

    \vspace{0.5em}

    \begin{itemize}
        \item<2-> Estas propiedades son fundamentales para teoría asintótica
        \item<3-> Permiten establecer tasas de convergencia en teoremas límite
    \end{itemize}
\end{frame}

\begin{frame}{Cadenas de Markov y $\beta$-Mezcla}
    \begin{theorem}
        Si una cadena de Markov es \textbf{geométricamente ergódica}, entonces es $\beta$-mezclada con:
        $$\beta(n) \leq C \rho^n$$
        para constantes $C > 0$ y $0 < \rho < 1$
    \end{theorem}

    \vspace{0.5em}

    \begin{itemize}
        \item<2-> Decaimiento \highlight{exponencial} de $\beta(n)$
        \item<3-> Muchas cadenas de Markov prácticas son geométricamente ergódicas
        \item<4-> Ejemplo: Metropolis-Hastings bajo condiciones regulares
    \end{itemize}
\end{frame}

\begin{frame}{Ejemplo: Metropolis-Hastings}
    El algoritmo MH genera cadena de Markov $\{X_t\}$ con:
    \begin{itemize}
        \item<1-> Propuesta: $Y \sim q(\cdot | X_t)$
        \item<2-> Probabilidad de aceptación:
        {\small $$\alpha(X_t, Y) = \min\left\{1, \frac{\pi(Y)q(X_t|Y)}{\pi(X_t)q(Y|X_t)}\right\}$$}
        \item<3-> Si aceptada: $X_{t+1} = Y$, si no: $X_{t+1} = X_t$
    \end{itemize}

    \vspace{0.5em}

    \begin{block}<4->{Ergodicidad Geométrica}
        Bajo condiciones de drift (Rosenthal 1995), MH es geométricamente ergódico, por tanto $\beta$-mezclado
    \end{block}
\end{frame}
